{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import mido\n",
    "import random\n",
    "import pretty_midi\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.models.bert.modeling_bert import BertAttention\n",
    "\n",
    "from figaro.models.vae import VqVaeModule\n",
    "from figaro.models.seq2seq import Seq2SeqModule\n",
    "from figaro.datasets import MidiDataset, SeqCollator\n",
    "from figaro.utils import medley_iterator\n",
    "from figaro.input_representation import remi2midi\n",
    "from figaro.input_representation import InputRepresentation\n",
    "from figaro.vocab import RemiVocab, DescriptionVocab\n",
    "from figaro.constants import (\n",
    "  PAD_TOKEN, BOS_TOKEN, EOS_TOKEN, BAR_KEY, POSITION_KEY,\n",
    "  TIME_SIGNATURE_KEY, INSTRUMENT_KEY, CHORD_KEY,\n",
    "  NOTE_DENSITY_KEY, MEAN_PITCH_KEY, MEAN_VELOCITY_KEY, MEAN_DURATION_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_old_or_new_checkpoint(model_class, checkpoint):\n",
    "    # assuming transformers>=4.36.0\n",
    "    pl_ckpt = torch.load(checkpoint, map_location=\"cpu\")\n",
    "    kwargs = pl_ckpt['hyper_parameters']\n",
    "    if 'flavor' in kwargs:\n",
    "        del kwargs['flavor']\n",
    "    if 'vae_run' in kwargs:\n",
    "        del kwargs['vae_run']\n",
    "    model = model_class(**kwargs)\n",
    "    state_dict = pl_ckpt['state_dict']\n",
    "    # position_ids are no longer saved in the state_dict starting with transformers==4.31.0\n",
    "    state_dict = {k: v for k, v in state_dict.items() if not k.endswith('embeddings.position_ids')}\n",
    "    try:\n",
    "        # succeeds for checkpoints trained with transformers>4.13.0\n",
    "        model.load_state_dict(state_dict)\n",
    "    except RuntimeError:\n",
    "        # work around a breaking change introduced in transformers==4.13.0, which fixed the position_embedding_type of cross-attention modules \"absolute\"\n",
    "        config = model.transformer.decoder.bert.config\n",
    "        for layer in model.transformer.decoder.bert.encoder.layer:\n",
    "            layer.crossattention = BertAttention(config, position_embedding_type=config.position_embedding_type)\n",
    "        model.load_state_dict(state_dict)\n",
    "    model.freeze()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model(checkpoint, vae_checkpoint=None, device='auto'):\n",
    "    if device == 'auto':\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    vae_module = None\n",
    "    if vae_checkpoint:\n",
    "        vae_module = load_old_or_new_checkpoint(VqVaeModule, vae_checkpoint)\n",
    "        vae_module.cpu()\n",
    "\n",
    "    model = load_old_or_new_checkpoint(Seq2SeqModule, checkpoint)\n",
    "    model.to(device)\n",
    "\n",
    "    return model, vae_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init the data module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Keep larger description alive and make it shift over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file_name):\n",
    "    vocab = RemiVocab()\n",
    "    desc_vocab = DescriptionVocab()\n",
    "    rep = InputRepresentation(file_name, strict=True)\n",
    "    events = rep.get_remi_events()\n",
    "    description = rep.get_description()\n",
    "\n",
    "    # Get Bar Ids\n",
    "    bars = [i for i, event in enumerate(events) if f\"{BAR_KEY}_\" in event]\n",
    "    bar_ids = torch.bincount(torch.tensor(bars, dtype=torch.int), minlength=len(events))\n",
    "    bar_ids = torch.cumsum(bar_ids, dim=0)\n",
    "\n",
    "    # Get positions\n",
    "    evnts = [f\"{POSITION_KEY}_0\" if f\"{BAR_KEY}_\" in event else event for event in events]\n",
    "    position_events = [event if f\"{POSITION_KEY}_\" in event else None for event in evnts]\n",
    "\n",
    "    positions = [int(pos.split('_')[-1]) if pos is not None else None for pos in position_events]\n",
    "\n",
    "    if positions[0] is None:\n",
    "        positions[0] = 0\n",
    "    for i in range(1, len(positions)):\n",
    "        if positions[i] is None:\n",
    "            positions[i] = positions[i-1]\n",
    "    position_ids = torch.tensor(positions, dtype=torch.int)\n",
    "\n",
    "    # Else\n",
    "    event_ids = torch.tensor(vocab.encode(events), dtype=torch.long)\n",
    "    bos = torch.tensor(vocab.encode([BOS_TOKEN]), dtype=torch.long)\n",
    "    eos = torch.tensor(vocab.encode([EOS_TOKEN]), dtype=torch.long)\n",
    "    zero = torch.tensor([0], dtype=torch.int)\n",
    "    event_ids = torch.cat([bos, event_ids, eos])\n",
    "    bar_ids = torch.cat([zero, bar_ids, zero])\n",
    "    position_ids = torch.cat([zero, position_ids, zero])\n",
    "\n",
    "    start, end = (0, len(event_ids))\n",
    "    src = event_ids[start:end]\n",
    "    b_ids = bar_ids[start:end]\n",
    "    p_ids = position_ids[start:end]\n",
    "\n",
    "    x = {\n",
    "        'input_ids': src,\n",
    "        'file': file_name,\n",
    "        'bar_ids': b_ids,\n",
    "        'position_ids': p_ids,\n",
    "    }\n",
    "\n",
    "    # Assume that bar_ids are in ascending order (except for EOS)\n",
    "    min_bar = b_ids[0]\n",
    "    desc_events = description\n",
    "    desc_bars = [i for i, event in enumerate(desc_events) if f\"{BAR_KEY}_\" in event]\n",
    "    # subtract one since first bar has id == 1\n",
    "    start_idx = desc_bars[max(0, min_bar - 1)]\n",
    "\n",
    "    desc_bar_ids = torch.zeros(len(desc_events), dtype=torch.int)\n",
    "    desc_bar_ids[desc_bars] = 1\n",
    "    desc_bar_ids = torch.cumsum(desc_bar_ids, dim=0)\n",
    "\n",
    "    desc_bos = torch.tensor(desc_vocab.encode([BOS_TOKEN]), dtype=torch.int)\n",
    "    desc_eos = torch.tensor(desc_vocab.encode([EOS_TOKEN]), dtype=torch.int)\n",
    "    desc_ids = torch.tensor(desc_vocab.encode(desc_events), dtype=torch.int)\n",
    "    if min_bar == 0:\n",
    "        desc_ids = torch.cat([desc_bos, desc_ids, desc_eos])\n",
    "        desc_bar_ids = torch.cat([zero, desc_bar_ids, zero])\n",
    "    else:\n",
    "        desc_ids = torch.cat([desc_ids, desc_eos])\n",
    "        desc_bar_ids = torch.cat([desc_bar_ids, zero])\n",
    "\n",
    "    x['description'] = desc_ids[start:]\n",
    "    x['desc_bar_ids'] = desc_bar_ids[start:]\n",
    "    # x = {k:(v[:ctx] if isinstance(v, torch.Tensor) else v) for k,v in x.items()}\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling feature:\n",
    "TODO: impl proper next note generation tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 16000\n",
    "max_bars = 1\n",
    "temperature = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def sample(model, batch, temperature = 1.2, max_iter = 16000, max_bars = 1, initial_prompt = 1):\n",
    "    batch_size, seq_len = batch['input_ids'].shape[:2]\n",
    "    batch_ = { key: batch[key][:, :initial_prompt] for key in ['input_ids', 'bar_ids', 'position_ids'] }\n",
    "    if model.description_flavor in ['description', 'both']:\n",
    "        batch_['description'] = batch['description']\n",
    "        batch_['desc_bar_ids'] = batch['desc_bar_ids']\n",
    "\n",
    "    max_len = seq_len + 1024\n",
    "    if max_iter > 0:\n",
    "        max_len = min(max_len, initial_prompt + max_iter)\n",
    "\n",
    "    pad_token_id = model.vocab.to_i(PAD_TOKEN)\n",
    "    eos_token_id = model.vocab.to_i(EOS_TOKEN)\n",
    "\n",
    "    batch_size, curr_len = batch_['input_ids'].shape\n",
    "\n",
    "    i = curr_len - 1\n",
    "    x = batch_['input_ids']\n",
    "    bar_ids = batch_['bar_ids']\n",
    "    position_ids = batch_['position_ids']\n",
    "    assert x.shape[:2] == bar_ids.shape and x.shape[:2] == position_ids.shape, f\"Input, bar and position ids weren't of compatible shapes: {x.shape}, {bar_ids.shape}, {position_ids.shape}\"\n",
    "\n",
    "    z, desc_bar_ids = batch_['description'], batch_['desc_bar_ids'].to(model.device)\n",
    "\n",
    "    is_done = torch.zeros(batch_size, dtype=torch.bool)\n",
    "    encoder_hidden_states = None\n",
    "\n",
    "    curr_bars = torch.zeros(batch_size).to(model.device).fill_(-1)\n",
    "    for i in range(curr_len - 1, max_len):\n",
    "        x_ = x[:, -model.context_size:].to(model.device)\n",
    "        bar_ids_ = bar_ids[:, -model.context_size:].to(model.device)\n",
    "        position_ids_ = position_ids[:, -model.context_size:].to(model.device)\n",
    "\n",
    "        if model.description_flavor in ['description', 'both']:\n",
    "            if model.description_flavor == 'description':\n",
    "                desc = z\n",
    "            else:\n",
    "                desc = z['description']\n",
    "            \n",
    "            next_bars = bar_ids_[:, 0]\n",
    "            bars_changed = not (next_bars == curr_bars).all()\n",
    "            curr_bars = next_bars\n",
    "\n",
    "            if bars_changed:\n",
    "                z_ = torch.zeros(batch_size, model.context_size, dtype=torch.int)\n",
    "                desc_bar_ids_ = torch.zeros(batch_size, model.context_size, dtype=torch.int)\n",
    "\n",
    "                for j in range(batch_size):\n",
    "                    curr_bar = bar_ids_[j, 0]\n",
    "                    indices = torch.nonzero(desc_bar_ids[j] == curr_bar)\n",
    "                    if indices.size(0) > 0:\n",
    "                        idx = indices[0, 0]\n",
    "                    else:\n",
    "                        idx = desc.size(1) - 1\n",
    "\n",
    "                    offset = min(model.context_size, desc.size(1) - idx)\n",
    "\n",
    "                    z_[j, :offset] = desc[j, idx:idx+offset]\n",
    "                    desc_bar_ids_[j, :offset] = desc_bar_ids[j, idx:idx+offset]\n",
    "\n",
    "                z_, desc_bar_ids_ = z_.to(model.device), desc_bar_ids_.to(model.device)\n",
    "                encoder_hidden_states = model.encode(z_, desc_bar_ids_)\n",
    "\n",
    "        logits = model.decode(x_, bar_ids=bar_ids_, position_ids=position_ids_, encoder_hidden_states=encoder_hidden_states)\n",
    "\n",
    "        idx = min(model.context_size - 1, i)\n",
    "        logits = logits[:, idx] / temperature\n",
    "\n",
    "        pr = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        pr = pr.view(-1, pr.size(-1))\n",
    "\n",
    "        next_token_ids = torch.multinomial(pr, 1).view(-1).to(x.device)\n",
    "        next_tokens = model.vocab.decode(next_token_ids)\n",
    "\n",
    "        next_bars = torch.tensor([1 if f'{BAR_KEY}_' in token else 0 for token in next_tokens], dtype=torch.int)\n",
    "        next_bar_ids = bar_ids[:, i].clone() + next_bars\n",
    "\n",
    "        next_positions = [f\"{POSITION_KEY}_0\" if f'{BAR_KEY}_' in token else token for token in next_tokens]\n",
    "        next_positions = [int(token.split('_')[-1]) if f'{POSITION_KEY}_' in token else None for token in next_positions]\n",
    "        next_positions = [pos if next_pos is None else next_pos for pos, next_pos in zip(position_ids[:, i], next_positions)]\n",
    "        next_position_ids = torch.tensor(next_positions, dtype=torch.int)\n",
    "\n",
    "        is_done.masked_fill_((next_token_ids == eos_token_id).all(dim=-1), True)\n",
    "        next_token_ids[is_done] = pad_token_id\n",
    "        if max_bars > 0:\n",
    "            is_done.masked_fill_(next_bar_ids >= max_bars + 1, True)\n",
    "\n",
    "        x = torch.cat([x, next_token_ids.clone().unsqueeze(1)], dim=1)\n",
    "        bar_ids = torch.cat([bar_ids, next_bar_ids.unsqueeze(1)], dim=1)\n",
    "        position_ids = torch.cat([position_ids, next_position_ids.unsqueeze(1)], dim=1)\n",
    "\n",
    "        if torch.all(is_done):\n",
    "            break\n",
    "        # print()\n",
    "\n",
    "    return {\n",
    "        'sequences': x,\n",
    "        'bar_ids': bar_ids,\n",
    "        'position_ids': position_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vae_module = load_model('./checkpoints/figaro-expert.ckpt', './checkpoints/vq-vae.ckpt')\n",
    "model.to('mps')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.17367911338806255\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m current_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mido\u001b[38;5;241m.\u001b[39mopen_input(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLaunchkey Mini MK3 MIDI Port\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m inport, mido\u001b[38;5;241m.\u001b[39mopen_output(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIAC Driver Bus 1\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outport:\n\u001b[0;32m---> 18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minport\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mallowed_types\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/Figaro_Live/venv/lib/python3.11/site-packages/mido/ports.py:243\u001b[0m, in \u001b[0;36mBaseInput.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;66;03m# The port closed before or inside receive().\u001b[39;00m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;66;03m# (This makes the assumption that this is the reason,\u001b[39;00m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;66;03m# at the risk of masking other errors.)\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/Figaro_Live/venv/lib/python3.11/site-packages/mido/backends/rtmidi.py:152\u001b[0m, in \u001b[0;36mInput.receive\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 152\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpoll()\n",
      "File \u001b[0;32m~/projects/Figaro_Live/venv/lib/python3.11/site-packages/mido/backends/_parser_queue.py:43\u001b[0m, in \u001b[0;36mParserQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    allowed_types = ['note_on', 'note_off']\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    time_sig = pretty_midi.containers.TimeSignature(numerator=3, denominator=4, time=0)\n",
    "    pm.time_signature_changes.append(time_sig)\n",
    "    piano = pretty_midi.Instrument(program=0)\n",
    "\n",
    "    active_notes = {}\n",
    "\n",
    "    bars = 8\n",
    "    bpm = 100\n",
    "    length = (60 / 100) * 4 * bars # Play for 4 bars\n",
    "    s = None\n",
    "    current_time = None\n",
    "\n",
    "    with mido.open_input('Launchkey Mini MK3 MIDI Port') as inport, mido.open_output('IAC Driver Bus 1') as outport:\n",
    "        for message in inport:\n",
    "            if message.type in allowed_types:\n",
    "                outport.send(message)\n",
    "                if s is None:\n",
    "                    s = time.time()\n",
    "                    current_time = 0\n",
    "                elif s is not None:\n",
    "                    current_time = time.time() - s\n",
    "\n",
    "                if s is not None:\n",
    "                    if message.type == 'note_on' and message.velocity > 0:\n",
    "                        active_notes[message.note] = (current_time, message.velocity)\n",
    "                    elif message.type == 'note_off' or (message.type == 'note_on' and message.velocity == 0):\n",
    "                        if message.note in active_notes:\n",
    "                            start, velocity = active_notes.pop(message.note)\n",
    "                            note = pretty_midi.Note(\n",
    "                                velocity=velocity,\n",
    "                                pitch=message.note,\n",
    "                                start=start,\n",
    "                                end=current_time\n",
    "                            )\n",
    "                            piano.notes.append(note)\n",
    "\n",
    "            if s is not None:\n",
    "                if time.time() - s >= length:\n",
    "                    current_time = time.time() - s\n",
    "                    for note, (_, velo) in active_notes.items():\n",
    "                        mido.Message('note_off', channel=0, note=note, velocity=velo, time=current_time)\n",
    "                        outport.send(message)\n",
    "                        note = pretty_midi.Note(\n",
    "                            velocity=velocity,\n",
    "                            pitch=note,\n",
    "                            start=start,\n",
    "                            end=current_time\n",
    "                        )\n",
    "                        piano.notes.append(note)\n",
    "                    break\n",
    "            if current_time is not None:\n",
    "                print(current_time, end='\\r')\n",
    "\n",
    "    pm.instruments.append(piano)\n",
    "\n",
    "    x = get_features(pm)\n",
    "    batch = {k:((v[None, :] if len(v.size()) == 1 else v) if isinstance(v,torch.Tensor) else v) for k,v in x.items()}\n",
    "    s = sample(model, batch, temperature, max_iter, 4, 1)\n",
    "    events_hat = model.vocab.decode(s['sequences'].detach().cpu()[0])\n",
    "    pm_hat = remi2midi(events_hat)\n",
    "\n",
    "    # Build a list of events: each note creates a note_on and note_off event\n",
    "    events = []\n",
    "    for instrument in pm_hat.instruments:\n",
    "        for note in instrument.notes:\n",
    "            # Each event is a tuple: (event_time, event_type, note)\n",
    "            events.append((note.start, 'note_on', note))\n",
    "            events.append((note.end, 'note_off', note))\n",
    "\n",
    "    # Sort events by their scheduled time\n",
    "    events.sort(key=lambda event: event[0])\n",
    "\n",
    "    with mido.open_output('IAC Driver Bus 1') as outport:\n",
    "        start_time = time.time()\n",
    "        for event_time, event_type, note in events:\n",
    "            # Wait until it's time for the event\n",
    "            current_time = time.time() - start_time\n",
    "            wait_time = event_time - current_time\n",
    "            if wait_time > 0:\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "            # Create the appropriate mido message for the event\n",
    "            if event_type == 'note_on':\n",
    "                msg = mido.Message('note_on', note=note.pitch, velocity=note.velocity)\n",
    "            else:  # 'note_off'\n",
    "                msg = mido.Message('note_off', note=note.pitch, velocity=0)\n",
    "\n",
    "            outport.send(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates a single note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.vocab.decode(batch['input_ids'][0].detach().cpu())\n",
    "for i in range(10):\n",
    "    with torch.no_grad():\n",
    "        batch_ = batch\n",
    "        s = sample(model, batch_, temperature, max_iter, 4, 1)\n",
    "\n",
    "        e = e[:-1] + model.vocab.decode(s['sequences'][0].detach().cpu())[1:]\n",
    "\n",
    "        xs_hat = torch.cat((batch['input_ids'], s['sequences']), dim=1).detach().cpu()\n",
    "        # xs_hat = s['sequences'].detach().cpu()\n",
    "        events_hat = model.vocab.decode(xs_hat[0])\n",
    "        \n",
    "        pm_hat = remi2midi(events_hat) # For the next generating etc.\n",
    "        x = get_features(pm_hat)\n",
    "        # Shift the tokens one over:\n",
    "\n",
    "        batch = {k:((v[None, :] if len(v.size()) == 1 else v) if isinstance(v,torch.Tensor) else v) for k,v in x.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_hat = remi2midi(e) # For the next generating etc.\n",
    "\n",
    "pm_hat.write('./text.midi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
